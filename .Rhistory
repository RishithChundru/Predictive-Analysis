ylab("Accuracy (%)")
model_accuracies <- data.frame(
Model = c("Naive Bayes", "Decision Tree", "SVM", "Neural Network", "K-Means"),
Accuracy = c(accuracy_naive * 100, accuracy_decision * 100, accuracy_svm * 100, accuracy_nn * 100, accuracy_kmeans * 100)
)
# Bar Plot
ggplot(model_accuracies, aes(x = Model, y = Accuracy, fill = Model)) +geom_bar(stat = "identity") +
geom_text(aes(label = round(Accuracy, 2)), vjust = -0.5, size = 5)+
ggtitle("Model Accuracy Comparison") +
xlab("Model") +
ylab("Accuracy (%)")
# Bar Plot
ggplot(model_accuracies, aes(x = Model, y = Accuracy, fill = Model)) +geom_bar(stat = "identity") +
geom_text(aes(label = round(Accuracy, 2)), vjust = -0.5, size = 5)+
ggtitle("Model Accuracy Comparison") +
xlab("Model") +
ylab("Accuracy (%)")
# Change the targeted column to factor
a$test_preparation_course <- factor(a$test_preparation_course)
# Showing the levels in targeted column
factor(a$test_preparation_course)
indexes <- sample(1:nrow(a),0.7*nrow(a))
# Testing Data
testing <- a[indexes,]
# Training Data
training <- a[-indexes,]
install.packages("e1071")
install.packages("e1071")
library(e1071)
# Naive Bayes function
naivebayes <- naiveBayes(test_preparation_course ~ math_score + reading_score + writing_score, data=training)
# performing naivebayes predictions on testing data
naivebayes_predictions <- predict(naivebayes,testing)
# Confusion Matrix
confusion_matrix <- table(testing$test_preparation_course,naivebayes_predictions)
print(confusion_matrix)
accuracy_naive=sum(diag(confusion_matrix))/sum(confusion_matrix)
print(paste("Naive Bayes Accuracy : ", round(accuracy*100,2),"%"))
# Storing it in the dataframe
df <- as.data.frame(confusion_matrix)
colnames(df) <- c('Actual','Predicted','Count')
library(ggplot2)
# Representing confusion matrix in a Heat Map
ggplot(df, aes(x = Predicted, y = Actual, fill = Count)) +
geom_tile() +
geom_text(aes(label = Count), color = "white", size = 5) +
scale_fill_gradient(low = "lightblue", high = "darkblue") +
ggtitle("Naive Bayes Confusion Matrix Heatmap") +
xlab("Predicted Class") +
ylab("Actual Class")
library(rpart)
decision_tree <- rpart(test_preparation_course ~ math_score + reading_score + writing_score,data=training,method = "class")
# Decision tree predictions
decision_tree_predictions <- predict(decision_tree,testing,type="class")
# Confusion Matrix
confusion_matrix1 <- table(testing$test_preparation_course,decision_tree_predictions)
print(confusion_matrix1)
df <- as.data.frame(confusion_matrix1)
colnames(df) <- c('Actual','Predicted','Count')
library(ggplot2)
# Representing confusion matrix in a Heat Map
ggplot(df, aes(x = Predicted, y = Actual, fill = Count)) +
geom_tile() +
geom_text(aes(label = Count), color = "white", size = 5) +
scale_fill_gradient(low = "lightblue", high = "darkblue") +
ggtitle("Decision Tree Confusion Matrix Heatmap") +
xlab("Predicted Class") +
ylab("Actual Class")
# Accuracy of Decision tree model
accuracy_decision <- sum(diag(confusion_matrix1))/sum(confusion_matrix1)
print(paste("Decision Tree Accuracy : ", round(accuracy1*100,2),"%"))
library(rpart.plot)
# Decision Tree
rpart.plot(decision_tree)
library(caTools)
a$test_preparation_course <- factor(a$test_preparation_course)
set.seed(123)
split <- sample.split(a$test_preparation_course, SplitRatio = 0.7)
training_set <- subset(a, split == TRUE)
testing_set <- subset(a, split == FALSE)
str(training_set)
# Feature scaling (excluding target variable)
numeric_cols <- sapply(training_set, is.numeric)
training_set[numeric_cols] <- scale(training_set[numeric_cols])
testing_set[numeric_cols] <- scale(testing_set[numeric_cols])
library(e1071)
# Build Svm classifier
classifier <- svm(
formula = test_preparation_course ~ math_score + reading_score + writing_score,
data = training_set,
type = 'C-classification',
kernel = 'linear'
)
# Predicting the testing set results
y_pred <- predict(classifier, newdata = testing_set[-5])
# Confusion Matrix
confusion_matrix_svm <- table(testing_set$test_preparation_course, y_pred)
print(confusion_matrix_svm)
# Calculate SVM Accuracy
accuracy_svm <- sum(diag(confusion_matrix_svm)) / sum(confusion_matrix_svm)
print(paste("SVM Accuracy : ", round(accuracy_svm * 100, 2), "%"))
df_svm <- as.data.frame(confusion_matrix_svm)
colnames(df_svm) <- c('Actual', 'Predicted', 'Count')
library(ggplot2)
ggplot(df_svm, aes(x = Predicted, y = Actual, fill = Count)) +
geom_tile() +
geom_text(aes(label = Count), color = "white", size = 5) +
scale_fill_gradient(low = "lightblue", high = "darkblue") +
ggtitle("SVM Confusion Matrix Heatmap") +
xlab("Predicted Class") +
ylab("Actual Class")
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
numeric_cols1 <- sapply(a, is.numeric)
# Apply normalization only to numeric columns
a_norm <- as.data.frame(a) # Copy the original dataframe
a_norm[numeric_cols] <- lapply(a[numeric_cols], normalize)
# Splitting the dataset
train_idx <- 1:round(0.7 * nrow(a_norm))
concrete_train <- a_norm[train_idx, ]
concrete_test <- a_norm[-train_idx, ]
library(neuralnet)
# Build Neural Network
neural_model <- neuralnet(test_preparation_course ~ math_score + reading_score + writing_score,
data = concrete_train,
hidden = 5,
stepmax = 1e6,
rep = 1)
plot(neural_model)
# Predicting results using the neural network model
prediction_nn <- predict(neural_model, concrete_test)
# Confusion Matrix
confusion_matrix_nn <- table(concrete_test$test_preparation_course, prediction_nn)
print(confusion_matrix_nn)
# Calculatin Accuracy
accuracy_nn <- sum(diag(confusion_matrix_nn)) / sum(confusion_matrix_nn)
print(paste("Neural Network Accuracy : ", round(accuracy_nn * 100, 2), "%"))
# Heatmap Visualization
df_nn <- as.data.frame(confusion_matrix_nn)
colnames(df_nn) <- c('Actual', 'Predicted', 'Count')
library(ggplot2)
ggplot(df_nn, aes(x = Predicted, y = Actual, fill = Count)) +
geom_tile() +
geom_text(aes(label = Count), color = "white", size = 5) +
scale_fill_gradient(low = "lightblue", high = "darkblue") +
ggtitle("Neural Network Confusion Matrix Heatmap") +
xlab("Predicted Class") +
ylab("Actual Class")
library(arules)
library(cluster)
a_1=a[,-5]
set.seed(240)
kmeans_result <- kmeans(a[, c("math_score", "reading_score", "writing_score")], centers = 3, nstart = 20)
kmeans_result
print(kmeans_result$cluster)
print(kmeans_result$centers)
cm<-table(a$test_preparation_course,kmeans_result$cluster)
cm
plot(a_1[c("reading_score","writing_score")],
col=kmeans_result$cluster,
main="K-Means Clustering of Math, Reading, and Writing Scores"
)
# K-means Clustering
clusplot(a[, c("reading_score", "writing_score")],
kmeans_result$cluster,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 2,
plotchar = FALSE,
span = TRUE,
main = "K-Means Clustering of Students",
xlab = "Reading Score",
ylab = "Writing Score")
# Confusion Matrix
confusion_matrix_kmeans <- table(a$test_preparation_course, kmeans_result$cluster)
print(confusion_matrix_kmeans)
# Calculating Accuracy
accuracy_kmeans <- sum(diag(confusion_matrix_kmeans)) / sum(confusion_matrix_kmeans)
print(paste("K-Means Clustering Accuracy : ", round(accuracy_kmeans * 100, 2), "%"))
# Confusion matrix Visualization
df_kmeans <- as.data.frame(confusion_matrix_kmeans)
colnames(df_kmeans) <- c('Actual', 'Predicted', 'Count')
library(ggplot2)
ggplot(df_kmeans, aes(x = Predicted, y = Actual, fill = Count)) +
geom_tile() +
geom_text(aes(label = Count), color = "white", size = 5) +
scale_fill_gradient(low = "lightblue", high = "darkblue") +
ggtitle("K-Means Confusion Matrix Heatmap") +
xlab("Predicted Class") +
ylab("Actual Class")
model_accuracies <- data.frame(
Model = c("Naive Bayes", "Decision Tree", "SVM", "Neural Network", "K-Means"),
Accuracy = c(accuracy_naive * 100, accuracy_decision * 100, accuracy_svm * 100, accuracy_nn * 100, accuracy_kmeans * 100)
)
# Bar Plot
ggplot(model_accuracies, aes(x = Model, y = Accuracy, fill = Model)) +geom_bar(stat = "identity") +
geom_text(aes(label = round(Accuracy, 2)), vjust = -0.5, size = 5)+
ggtitle("Model Accuracy Comparison") +
xlab("Model") +
ylab("Accuracy (%)")
View(a)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
numeric_cols1 <- sapply(a, is.numeric)
# Apply normalization only to numeric columns
a_norm <- as.data.frame(a) # Copy the original dataframe
a_norm[numeric_cols] <- lapply(a[numeric_cols], normalize)
# Splitting the dataset
train_idx <- 1:round(0.7 * nrow(a_norm))
ann_train <- a_norm[train_idx, ]
ann_test <- a_norm[-train_idx, ]
# Install and load the neuralnet package
install.packages("neuralnet")
install.packages("neuralnet")
library(neuralnet)
# Build Neural Network
neural_model <- neuralnet(test_preparation_course ~ math_score + reading_score + writing_score,
data = ann_train,
hidden = 5,
stepmax = 1e6,
rep = 1)
# Predicting results using the neural network model
prediction_nn <- predict(neural_model, ann_test)
# Confusion Matrix
confusion_matrix_nn <- table(ann_test$test_preparation_course, prediction_nn)
print(confusion_matrix_nn)
# Calculatin Accuracy
accuracy_nn <- sum(diag(confusion_matrix_nn)) / sum(confusion_matrix_nn)
print(paste("Neural Network Accuracy : ", round(accuracy_nn * 100, 2), "%"))
ann_results<-compute(neural_model,concrete_test)
ann_pred_fraud<-ann_results$net.result
ann_results<-compute(neural_model,concrete_test)
ann_pred<-ann_results$net.result
cor(ann_pred,ann_test$test_preparation_course)
ch<-as.numeric(ann_test$test_preparation_course)
ann_results<-compute(neural_model,concrete_test)
ann_pred<-ann_results$net.result
cor(ann_pred,ann_test$test_preparation_course)
ch<-as.numeric(ann_test$test_preparation_course)
ann_results<-compute(neural_model,concrete_test)
ann_pred<-ann_results$net.result
cor(ann_pred,ch)
itemFrequencyPlot(groceries, support = 0.1)
install.packages("randomforest")
randomForest?
randomForest?
install.packages("randomForest")
install.packages("randomForest")
?randomForest
randomForest?
library(randomForest)
install.packages("randomForest")
library(randomForest)
data("iris")
data(iris)
set.seed(42)
sample_index<-sample(1:nrow(iris),0.7*nrow(iris))
train_data<-iris[sample_index,]
test_data<-iris[-sample_index,]
rf_model=randomForest(Species~.,data = train_data,ntree=100)
predictions<-predict(rf_model,test_data)
confusion_matrix<-table(predictions,test_data$Species)
print(confusion_matrix)
plot(rf_model)
accuracy<-sum(diag(confusion_matrix))/sum(confusion_matrix)
print(paste("Accuracy is: "+round(accuracy*100,2),"%"))
print(paste("Accuracy is: ",round(accuracy*100,2),"%"))
a<-10
a
class(a)
typeof(a)
a<-10
a
class(a)
typeof(a)
b<-23.4
b
class(b)
typeof(b)
c<-10L
c
class(c)
typeof(c)
d<-"hi"
d
class(d)
typeof(d)
e<-3+4i
e
class(e)
typeof(e)
f<-TRUE
f
class(f)
typeof(f)
# Assigning
a<-b<-10
a
b
cat("the value of a is",a,"the value of b is",b)
paste(a,b)
print(c(a,b))
a<-c(20L,TRUE)
a
class(a)
## Arithmetic operations
a<-c(1,2,3,4,5)
b<-c(6,7,8,9,0)
print(c(a+b,a-b,a*b,a/b,a%/%b,a%%b,a^b))
print(a-b)
print(a*b)
print(a/b)
print(a%/%b)
print(a%%b)
print(a^b)
a<-c('Sai','Ram','Jay')
b<-c(34.5,36.7,35.4)
c<-c(TRUE,TRUE, FALSE)
b[2:3]
b[-2]
a[1:2]
d<-b[c==TRUE]
print(d)
# Relational Operators
a<-c(TRUE,TRUE,FALSE,FALSE)
b<-c(TRUE,FALSE,TRUE,FALSE)
print(a&b)
print(a|b)
print(!a)
print(a&&b)
print(a||b)
# WAP to find a number is  even or odd
{
a<-as.numeric(readline())
if(a%%2==0){
print("Even")
}else{
print("Odd")
}
}
a<-1
b<-2
c<-3
if(((b*b)-4*a*c)==0){
r1<--b/2*a
r2<--b/2*a
print(r1)
print(r2)
print("roots are real and equal")
}else if(((b*b)-4*a*c)>0){
r1<-(-b-(a**1/2))/2*a
r2<-(-b+(a**1/2))/2*a
print("Roots are real and distinct")
}else{
print("Roots are imaginary")
}
# wap to find roots of quadratic equation
{
a<-1
b<-2
c<-3
if(((b*b)-4*a*c)==0){
r1<--b/2*a
r2<--b/2*a
print(r1)
print(r2)
print("roots are real and equal")
}else if(((b*b)-4*a*c)>0){
r1<-(-b-(a**1/2))/2*a
r2<-(-b+(a**1/2))/2*a
print("Roots are real and distinct")
}else{
print("Roots are imaginary")
}
}
a<-read.csv(file.choose())
View(a)
b<-na.omit(a)
View(b)
# Remove duplicate rows
data <- a[!duplicated(a), ]
data
data
# Rename a column
colnames(a)[colnames(a) == "Order.Date"] <- "Date"
View(a)
# Remove leading/trailing white spaces in a specific column
a$Customer.Name <- trimws(a$Customer.Name)
# Convert text to lowercase
a$Ship.Mode <- tolower(a$Ship.Mode)
# Convert text to uppercase
a$Ship.Mode <- toupper(a$Ship.Mode)
View(a)
# Replacing the missing values with the mean value of each variable
a$Sales[is.na(a$Sales)]<-mean(a$Sales,na.rm=TRUE)
View(a)
View(a)
# Replacing the missing values with random value between min and max of each variable
a$Sales[is.na(a$Sales)]<-runif(n=sum(is.na(a$Sales)),
min=min(a$Sales,na.rm=TRUE),
max=max(a$Sales,na.rm=TRUE))
View(a)
# Missing values for categorical variables by random value from each variable
# Convert to factor if not already
a$Order.Priority <- as.factor(a$Order.Priority)
View(a$Order.Priority)
a$Order.Priority
# Replace NA values with random levels from the factor
a$Order.Priority[is.na(a$Order.Priority)] <- sample(
levels(a$Order.Priority),
size = sum(is.na(a$Order.Priority)),
replace = TRUE
)
# View the result
View(a)
row<-c('row1','row2')
col<-c('col1','col2','col3')
matrix1<-matrix(1:6,nrow=2,ncol=3,dimnames = list(row,col))
matrix2<-matrix(7:12,nrow=2,ncol=3,dimnames=list(row,col))
matrix1
matrix2
matrix1+matrix2
matrix1[1,]
matrix2[2,3]
{
a<-readline("Enter a number: ");
b=1;
if(a==0){
b=1;
}else{
for(i in 1:a){
b=b*i;
}
}
print(b)
}
v1<-c("North","East","North","East","East")
a<-as.factor(v1)
a
# create a list having 4 kinds of datatypes: string, vector, logical and numeric. After printing data items of these list. add an item to this existing list. enter any random string find out whether the string is present in given list or not. Remove third item from the existing list.
a<-list("Ram",c(1,2,3),TRUE,23.45)
a
a[5]=12
a
a%in%"Ram"
a[-3]
a<-matrix(1:8,nrow=2,ncol=4)
b<-matrix(9:16,nrow=2,ncol=4)
a
dim(a)
t(a)
t(b)
a*b
a<-data.frame(name=c("Ram","Sai","kiran","varun","soumya"),
age=c(19,20,34,21,29),
gender=c("Male","Male","Male","Male","Female"))
a
occupations=c("Employee","Teacher","Farmer","Daily Wager","Businessman")
cbind(a,occupations)
b<-a[a[2]>25]
b
# transpose
a <- matrix(1:8, nrow=2, ncol=4)
b <- matrix(9:16, nrow=2, ncol=4)
a
for (j in 1:ncol) {
result[i, j] <- mat[j, i]
}
for (i in 1:nrow) {
for (j in 1:ncol) {
result[i, j] <- mat[j, i]
}
}
return(result)
transpose_matrix <- function(mat) {
nrow <- ncol(mat)
ncol <- nrow(mat)
result <- matrix(0, nrow=nrow, ncol=ncol)
for (i in 1:nrow) {
for (j in 1:ncol) {
result[i, j] <- mat[j, i]
}
}
return(result)
}
a_transposed <- transpose_matrix(a)
b_transposed <- transpose_matrix(b)
print(a_transposed)
Åprint(b_transposed)
print(b_transposed)
a<-iris
diff(range(iris$Petal.Width))
quantile(iris$Petal.Width,seq(from=0,to=1,by=0.30))
table(iris$Sepal.Length)
b<-table(iris$Petal.Width)
prop.table(b)
getwd()
data<-data.frame(Name=c("Sai","Ram","Shyam"),
age=c(12,13,15))
data
save(data,file="abc.csv")
setwd("C:/College PPTs/5th SEM/INT234")
write.csv(data,file="abc.csv",row.names=FALSE)
ls()
rm(a,c)
ls()
write.csv(data,file="abc.csv",row.names=FALSE)
mydata<-read.csv("abc.csv")
View(mydata)
