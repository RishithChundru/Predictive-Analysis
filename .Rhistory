b_count
table(data$diagnosis)
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
data$diagnosis[data$diagnosis == "B"] = "Benign"
data$diagnosis[data$diagnosis == "M"] = "Malignant"
View(data)
table(data$diagnosis)
summary(data$radius_mean)
summary(data$area_mean)
summary(data$smoothness_mean)
install.packages("gmodels")
install.packages("gmodels")
library(gmodels)
normalize<-function(x){
return ((x-min(x))/max(x)-min(x))
}
data$radius_mean <- normalize(data$radius_mean)
data$area_mean <- normalize(data$area_mean)
data$smoothness_mean <- normalize(data$smoothness_mean)
View(data)
library(class)
set.seed(123)
trainIndex <- sample(1: nrow(data),0.7*nrow(data))
trainIndex
train <- data[trainIndex,]
test <- data[-trainIndex,]
train
test
knn_pred <- knn(train[,-1],test[,-1],train$diagnosis,k=100)
table(knn_pred,test$diagnosis,dnn = c("prediction","actual"))
Accuracy<- sum(knn_pred==test$diagnosis)/nrow(test)
Accuracy
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
a<-diamonds
View(a)
table(a$color)
a$depth[is.na(a$depth)]<-mean(a$depth,na.rm = TRUE)
View(a)
summary(a$depth)
summary(a$table)
summary(a$price)
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
a<-diamonds
View(a)
table(a$color)
a$depth[is.na(a$depth)]<-mean(a$depth,na.rm = TRUE)
View(a)
summary(a$depth)
summary(a$table)
summary(a$price)
install.packages("gmodels")
library(gmodels)
normalize<-function(x){
return ((x-min(x))/(max(x)-min(x)))
}
b<-normalize(a$price)
b
c<-normalize(a$x)
c<-normalize(a$x)
c
d<-sample(1:nrow(a),0.7*nrow(a))
d
train<-a[d,]
test<-a[-d,]
train
test
table(knn_pred,test$x,dnn = c("prediction","actual"))
Accuracy<- sum(knn_pred==test$x)/nrow(test)
Accuracy
a<-read.csv(file.choose())
a
head(a)
b<-na.omit(a)
View(b)
a$Gender[a$Gender=="M"]="Male"
a$Gender[a$Gender=="F"]="Female"
a$Salary[a$Salary=="Fifty Thousand"]="55000"
a$Survey_Score[a$Survey_Score=="four"]="4"
View(a)
a$Gender<-as.factor(a$Gender)
a$Gender[is.na(a$Gender)] <- sample(
levels(a$Gender),
size = sum(is.na(a$Gender)),
replace = TRUE
)
View(a)
a$Survey[is.na(a$Survey)]<-mean(a$Survey,na.rm=TRUE)
View(a)
install.packages("rpart")
library("rpart")
data("iris")
str(iris)
# Sample(150,110) would mean selecting 110 random
# elements from a population of 150 unique elements
indexes=sample(150,110)
data("iris")
str(iris)
# Sample(150,110) would mean selecting 110 random
# elements from a population of 150 unique elements
indexes=sample(150,110)
indexes
iris_train=iris[indexes,]
iris_train
iris_test=iris[-indexes,]
iris_test
data("iris")
View(iris)
target=s=Species-Sepal.Length-Sepal.Width-Petal.Length-Petal.Width
target=Species-Sepal.Length-Sepal.Width-Petal.Length-Petal.Width
target=species-Sepal.Length-Sepal.Width-Petal.Length-Petal.Width
target<-Species-Sepal.Length-Sepal.Width-Petal.Length-Petal.Width
target
target<-Species-Sepal.Length+Sepal.Width+Petal.Length+Petal.Width
#The "class" method is used when the target variable is
#categorical (e.g., predicting species of flowers).
tree=rpart(target,data=iris_train,method="class")
install.packages("rpart.plot")
library("rpart.plot")
target<-Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width
target
#The "class" method is used when the target variable is
#categorical (e.g., predicting species of flowers).
tree=rpart(target,data=iris_train,method="class")
install.packages("rpart.plot")
predictions=predict(tree,iris_test,type="class")
predictions
actual=iris_test$Species
rpart.plot(tree)
trainIndex <- sample(1: nrow(data),0.7*nrow(data))
trainIndex
train <- data[trainIndex,]
test <- data[-trainIndex,]
train
test
knn_pred <- knn(train[,-1],test[,-1],train$quality,k=162)
table(knn_pred,test$quality,dnn = c("prediction","actual"))
Accuracy<- sum(knn_pred==test$quality)/nrow(test)
Accuracy
# Knn
setwd("C:/College PPTs/5th SEM/INT234")
library(readxl)
data=read_excel("winequality_red.xlsx")
View(data)
three_count<-sum(data$quality=="3")
four_count <- sum(data$quality == "4")
five_count <- sum(data$quality == "5")
six_count <- sum(data$quality == "6")
seven_count <- sum(data$quality == "7")
eight_count <- sum(data$quality == "8")
three_count
four_count
five_count
six_count
seven_count
eight_count
table(data$quality)
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
mutating<- data %>%
mutate(quality = recode(quality, "3"="three" ,"4" = "four", "5" ="five", "6"="six","7"="seven","8"="eight"))
mutating
View(mutating)
summary(data$density)
summary(data$pH)
summary(data$sulphates)
install.packages("gmodels")
install.packages("gmodels")
library(gmodels)
normalize<-function(x){
return ((x-min(x))/max(x)-min(x))
}
data$density <- normalize(data$density)
data$pH <- normalize(data$pH)
data$sulphates <- normalize(data$sulphates)
View(data)
library(class)
set.seed(123)
trainIndex <- sample(1: nrow(data),0.7*nrow(data))
trainIndex
train <- data[trainIndex,]
test <- data[-trainIndex,]
train
test
knn_pred <- knn(train[,-1],test[,-1],train$quality,k=162)
table(knn_pred,test$quality,dnn = c("prediction","actual"))
Accuracy<- sum(knn_pred==test$quality)/nrow(test)
Accuracy
# Naive Bayes
View(data)
str(data)
data$quality=factor(data$quality)
install.packages("tm")
install.packages("tm")
install.packages("tm")
install.packages("tm")
install.packages("tm")
library(tm)
sms_corpus=VCorpus(VectorSource(data$alcohol))
print(sms_corpus)
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:2],as.character)
sms_corpus_clean=tm_map(sms_corpus,content_transformer(tolower))
print(sms_corpus_clean)
sms_corpus=VCorpus(VectorSource(mutating))
print(sms_corpus)
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:2],as.character)
sms_corpus_clean=tm_map(sms_corpus,content_transformer(tolower))
print(sms_corpus_clean)
sms_corpus=VCorpus(VectorSource(data$alcohol))
print(sms_corpus)
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:2],as.character)
sms_corpus_clean=tm_map(sms_corpus,content_transformer(tolower))
print(sms_corpus_clean)
as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]])
sms_corpus_clean=tm_map(sms_corpus_clean,removeNumbers)
print(sms_corpus_clean)
as.character(sms_corpus_clean[[3]])
sms_corpus_clean=tm_map(sms_corpus_clean,removeWords,stopwords())
sms_corpus_clean=tm_map(sms_corpus_clean,removePunctuation)
install.packages("SnowballC")
library(SnowballC)
sms_corpus_clean=tm_map(sms_corpus_clean,stemDocument)
sms_corpus_clean=tm_map(sms_corpus_clean,stripWhitespace)
sms_dtm=DocumentTermMatrix(sms_corpus_clean)
sms_dtm_train=sms_dtm[1:81,]
sms_dtm_test=sms_dtm[82:162,]
sms_train_labels=a[1:81,]$alcohol
sms_test_labels=a[82:162,]$alcohol
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
install.packages("wordcloud")
library(wordcloud)
wordcloud(sms_corpus_clean,min.freq = 50,random.order = FALSE )
sms_corpus=VCorpus(VectorSource(mutating))
print(sms_corpus)
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:2],as.character)
sms_corpus_clean=tm_map(sms_corpus,content_transformer(tolower))
print(sms_corpus_clean)
as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]])
sms_corpus_clean=tm_map(sms_corpus_clean,removeNumbers)
print(sms_corpus_clean)
as.character(sms_corpus_clean[[3]])
sms_corpus_clean=tm_map(sms_corpus_clean,removeWords,stopwords())
sms_corpus_clean=tm_map(sms_corpus_clean,removePunctuation)
install.packages("SnowballC")
sms_corpus_clean=tm_map(sms_corpus_clean,stemDocument)
sms_corpus_clean=tm_map(sms_corpus_clean,stripWhitespace)
sms_dtm=DocumentTermMatrix(sms_corpus_clean)
sms_dtm_train=sms_dtm[1:81,]
sms_dtm_train=sms_dtm[1:6,]
sms_dtm_test=sms_dtm[7:12,]
sms_train_labels=a[1:6,]$alcohol
sms_test_labels=a[7:12,]$alcohol
sms_train_labels=a[1:6,]$mutating
sms_test_labels=a[7:12,]$mutating
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
wordcloud(sms_corpus_clean,min.freq = 50,random.order = FALSE )
sms_freq_words<-findFreqTerms(sms_dtm_train,5)
str(sms_freq_words)
sms_dtm_freq_train=sms_dtm_train[ ,sms_freq_words]
sms_dtm_freq_test=sms_dtm_test[ ,sms_freq_words]
convert_counts<-function(x){
x<-ifelse(x>0,"Yes","No")
}
sms_train=apply(sms_dtm_freq_train,MARGIN = 2,convert_counts)
sms_test=apply(sms_dtm_freq_test,MARGIN = 2,convert_counts)
install.packages("e1071")
library(e1071)
sms_classifier<-naiveBayes(sms_train,sms_train_labels)
sms_test_pred<-predict(sms_classifier,sms_test)
sms_classifier
sms_test_pred
sms_train=apply(sms_dtm_freq_train,MARGIN = 4,convert_counts)
sms_test=apply(sms_dtm_freq_test,MARGIN = 4,convert_counts)
sms_test=apply(sms_dtm_freq_test,MARGIN = 12,convert_counts)
sms_train=apply(sms_dtm_freq_train,MARGIN = 2,convert_counts)
sms_test=apply(sms_dtm_freq_test,MARGIN = 2,convert_counts)
install.packages("e1071")
library(e1071)
sms_classifier<-naiveBayes(sms_train,sms_train_labels)
install.packages("e1071")
install.packages("e1071")
sms_classifier<-naiveBayes(sms_train,sms_train_labels)
sms_test_pred<-predict(sms_classifier,sms_test)
sms_corpus=VCorpus(VectorSource(quality))
print(sms_corpus)
mutating
mutating
mutating
mutating
sms_corpus=VCorpus(VectorSource(mutating))
print(sms_corpus)
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:2],as.character)
sms_corpus_clean=tm_map(sms_corpus,content_transformer(tolower))
print(sms_corpus_clean)
as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]])
sms_corpus_clean=tm_map(sms_corpus_clean,removeNumbers)
print(sms_corpus_clean)
as.character(sms_corpus_clean[[3]])
sms_corpus_clean=tm_map(sms_corpus_clean,removeWords,stopwords())
sms_corpus_clean=tm_map(sms_corpus_clean,removePunctuation)
sms_corpus_clean=tm_map(sms_corpus_clean,stemDocument)
sms_corpus_clean=tm_map(sms_corpus_clean,stripWhitespace)
sms_dtm=DocumentTermMatrix(sms_corpus_clean)
sms_dtm_train=sms_dtm[1:6,]
sms_dtm_test=sms_dtm[7:12,]
sms_train_labels=a[1:6,]$mutating
sms_test_labels=a[7:12,]$mutating
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
wordcloud(sms_corpus_clean,min.freq = 50,random.order = FALSE )
sms_freq_words<-findFreqTerms(sms_dtm_train,5)
str(sms_freq_words)
sms_dtm_freq_train=sms_dtm_train[ ,sms_freq_words]
sms_dtm_freq_test=sms_dtm_test[ ,sms_freq_words]
convert_counts<-function(x){
x<-ifelse(x>0,"Yes","No")
}
sms_train=apply(sms_dtm_freq_train,MARGIN = 2,convert_counts)
sms_test=apply(sms_dtm_freq_test,MARGIN = 2,convert_counts)
sms_classifier<-naiveBayes(sms_train,sms_train_labels)
sms_test_pred<-predict(sms_classifier,sms_test)
#Decision tree
install.packages("rpart")
install.packages("rpart")
library("rpart")
View(data)
str(data)
indexes=sample(162,110)
indexes
data_train=data[indexes,]
data_train
data_test=data[-indexes,]
data_test
View(data)
target<-quality~fixed acidity+volatile acidity + citric acid + residual sugar + chlorides+free sulfur dioxide+total sulfur dioxide+density+pH+sulphates+alcohol+quality
target<-quality+fixed acidity+volatile acidity + citric acid + residual sugar + chlorides+free sulfur dioxide+total sulfur dioxide+density+pH+sulphates+alcohol+quality
target<-quality~chlorides+density+pH+sulphates
target
tree=rpart(target,data=data_train,method="class")
install.packages("rpart.plot")
library("rpart.plot")
predictions=predict(tree,data_test,type="class")
predictions
actual=iris_test$Species
actual=data_test$quality
rpart.plot(tree)
View(data)
three_count<-sum(data$quality=="3")
three_count<-sum(data$quality=="3")
four_count <- sum(data$quality == "4")
five_count <- sum(data$quality == "5")
six_count <- sum(data$quality == "6")
seven_count <- sum(data$quality == "7")
eight_count <- sum(data$quality == "8")
three_count
four_count
five_count
six_count
seven_count
eight_count
table(data$quality)
mutating<- data %>%
mutate(quality = recode(quality, "3"="three" ,"4" = "four", "5" ="five", "6"="six","7"="seven","8"="eight"))
mutating
View(mutating)
summary(data$density)
summary(data$pH)
summary(data$sulphates)
normalize<-function(x){
return ((x-min(x))/max(x)-min(x))
}
data$density <- normalize(data$density)
data$pH <- normalize(data$pH)
data$sulphates <- normalize(data$sulphates)
View(data)
trainIndex <- sample(1: nrow(data),0.7*nrow(data))
trainIndex
train <- data[trainIndex,]
test <- data[-trainIndex,]
train
test
knn_pred <- knn(train[,-1],test[,-1],train$quality,k=162)
table(knn_pred,test$quality,dnn = c("prediction","actual"))
Accuracy<- sum(knn_pred==test$quality)/nrow(test)
Accuracy
data$quality=factor(data$quality)
install.packages("tm")
data$quality=factor(data$quality)
sms_corpus=VCorpus(VectorSource(mutating))
install.packages("tm")
install.packages("tm")
install.packages("tm")
library(tm)
sms_corpus=VCorpus(VectorSource(mutating))
print(sms_corpus)
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:2],as.character)
sms_corpus_clean=tm_map(sms_corpus,content_transformer(tolower))
print(sms_corpus_clean)
as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]])
sms_corpus_clean=tm_map(sms_corpus_clean,removeNumbers)
print(sms_corpus_clean)
as.character(sms_corpus_clean[[3]])
sms_corpus_clean=tm_map(sms_corpus_clean,removeWords,stopwords())
sms_corpus_clean=tm_map(sms_corpus_clean,removePunctuation)
install.packages("SnowballC")
library(SnowballC)
sms_corpus_clean=tm_map(sms_corpus_clean,stemDocument)
sms_corpus_clean=tm_map(sms_corpus_clean,stripWhitespace)
sms_dtm=DocumentTermMatrix(sms_corpus_clean)
sms_dtm_train=sms_dtm[1:6,]
sms_dtm_test=sms_dtm[7:12,]
sms_train_labels=a[1:6,]$mutating
sms_test_labels=a[7:12,]$mutating
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
install.packages("wordcloud")
library(wordcloud)
wordcloud(sms_corpus_clean,min.freq = 50,random.order = FALSE )
sms_freq_words<-findFreqTerms(sms_dtm_train,5)
str(sms_freq_words)
sms_dtm_freq_train=sms_dtm_train[ ,sms_freq_words]
sms_dtm_freq_test=sms_dtm_test[ ,sms_freq_words]
x<-ifelse(x>0,"Yes","No")
convert_counts<-function(x){
x<-ifelse(x>0,"Yes","No")
}
sms_train=apply(sms_dtm_freq_train,MARGIN = 2,convert_counts)
sms_test=apply(sms_dtm_freq_test,MARGIN = 2,convert_counts)
install.packages("e1071")
library(e1071)
sms_classifier<-naiveBayes(sms_train,sms_train_labels)
sms_test_pred<-predict(sms_classifier,sms_test)
#Decision tree
install.packages("rpart")
install.packages("rpart")
library("rpart")
indexes=sample(162,110)
indexes
data_train=data[indexes,]
data_train
data_test=data[-indexes,]
data_test
target<-quality~chlorides+density+pH+sulphates
target
tree=rpart(target,data=data_train,method="class")
install.packages("rpart.plot")
library("rpart.plot")
predictions=predict(tree,data_test,type="class")
predictions
actual=data_test$quality
rpart.plot(tree)
rpart.plot(tree)
install.packages("rpart")
install.packages("rpart")
library("rpart")
data("iris")
View(iris)
str(iris)
# Sample(150,110) would mean selecting 110 random
# elements from a population of 150 unique elements
indexes=sample(150,110)
indexes
iris_train=iris[indexes,]
iris_train
iris_test=iris[-indexes,]
iris_test
target<-Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width
target
#The "class" method is used when the target variable is
#categorical (e.g., predicting species of flowers).
tree=rpart(target,data=iris_train,method="class")
install.packages("rpart.plot")
library("rpart.plot")
install.packages("rpart.plot")
install.packages("rpart.plot")
library("rpart.plot")
predictions=predict(tree,iris_test,type="class")
predictions
actual=iris_test$Species
rpart.plot(tree)
# step-7: evaluate the model performance by creating a confusion matrix
confusion_matrix<-table(iris_test$Species,predictions)
print(confusion_matrix)
# step-8: calculate the accuracy of the model
accuracy=sum(diag(confusion_matrix))/sum(confusion_matrix)  # the formula used is present in 'caret' library. this calculates the sum of diagonal values present in the confusion matrix divided by sum of all values present in confusion matrix
print(paste("Accuracy: ",round(accuracy*100,4)))
