shade = TRUE,
color = TRUE,
labels = 2,
plotchar = FALSE,
span = TRUE,
main = "K-Means Clustering of Students",
xlab = "Reading Score",
ylab = "Writing Score")
# Confusion Matrix
confusion_matrix_kmeans <- table(a$test_preparation_course, kmeans_result$cluster)
print(confusion_matrix_kmeans)
# Calculating Accuracy
accuracy_kmeans <- sum(diag(confusion_matrix_kmeans)) / sum(confusion_matrix_kmeans)
print(paste("K-Means Clustering Accuracy : ", round(accuracy_kmeans * 100, 2), "%"))
# Confusion matrix Visualization
df_kmeans <- as.data.frame(confusion_matrix_kmeans)
colnames(df_kmeans) <- c('Actual', 'Predicted', 'Count')
library(ggplot2)
ggplot(df_kmeans, aes(x = Predicted, y = Actual, fill = Count)) +
geom_tile() +
geom_text(aes(label = Count), color = "white", size = 5) +
scale_fill_gradient(low = "lightblue", high = "darkblue") +
ggtitle("K-Means Confusion Matrix Heatmap") +
xlab("Predicted Class") +
ylab("Actual Class")
model_accuracies <- data.frame(
Model = c("Naive Bayes", "Decision Tree", "SVM", "Neural Network", "K-Means"),
Accuracy = c(accuracy_naive * 100, accuracy_decision * 100, accuracy_svm * 100, accuracy_nn * 100, accuracy_kmeans * 100)
)
# Bar Plot
ggplot(model_accuracies, aes(x = Model, y = Accuracy, fill = Model)) +geom_bar(stat = "identity") +
geom_text(aes(label = round(Accuracy, 2)), vjust = -0.5, size = 5)+
ggtitle("Model Accuracy Comparison") +
xlab("Model") +
ylab("Accuracy (%)")
model_accuracies <- data.frame(
Model = c("Naive Bayes", "Decision Tree", "SVM", "Neural Network", "K-Means"),
Accuracy = c(accuracy_naive * 100, accuracy_decision * 100, accuracy_svm * 100, accuracy_nn * 100, accuracy_kmeans * 100)
)
# Bar Plot
ggplot(model_accuracies, aes(x = Model, y = Accuracy, fill = Model)) +geom_bar(stat = "identity") +
geom_text(aes(label = round(Accuracy, 2)), vjust = -0.5, size = 5)+
ggtitle("Model Accuracy Comparison") +
xlab("Model") +
ylab("Accuracy (%)")
# Bar Plot
ggplot(model_accuracies, aes(x = Model, y = Accuracy, fill = Model)) +geom_bar(stat = "identity") +
geom_text(aes(label = round(Accuracy, 2)), vjust = -0.5, size = 5)+
ggtitle("Model Accuracy Comparison") +
xlab("Model") +
ylab("Accuracy (%)")
# Change the targeted column to factor
a$test_preparation_course <- factor(a$test_preparation_course)
# Showing the levels in targeted column
factor(a$test_preparation_course)
indexes <- sample(1:nrow(a),0.7*nrow(a))
# Testing Data
testing <- a[indexes,]
# Training Data
training <- a[-indexes,]
install.packages("e1071")
install.packages("e1071")
library(e1071)
# Naive Bayes function
naivebayes <- naiveBayes(test_preparation_course ~ math_score + reading_score + writing_score, data=training)
# performing naivebayes predictions on testing data
naivebayes_predictions <- predict(naivebayes,testing)
# Confusion Matrix
confusion_matrix <- table(testing$test_preparation_course,naivebayes_predictions)
print(confusion_matrix)
accuracy_naive=sum(diag(confusion_matrix))/sum(confusion_matrix)
print(paste("Naive Bayes Accuracy : ", round(accuracy*100,2),"%"))
# Storing it in the dataframe
df <- as.data.frame(confusion_matrix)
colnames(df) <- c('Actual','Predicted','Count')
library(ggplot2)
# Representing confusion matrix in a Heat Map
ggplot(df, aes(x = Predicted, y = Actual, fill = Count)) +
geom_tile() +
geom_text(aes(label = Count), color = "white", size = 5) +
scale_fill_gradient(low = "lightblue", high = "darkblue") +
ggtitle("Naive Bayes Confusion Matrix Heatmap") +
xlab("Predicted Class") +
ylab("Actual Class")
library(rpart)
decision_tree <- rpart(test_preparation_course ~ math_score + reading_score + writing_score,data=training,method = "class")
# Decision tree predictions
decision_tree_predictions <- predict(decision_tree,testing,type="class")
# Confusion Matrix
confusion_matrix1 <- table(testing$test_preparation_course,decision_tree_predictions)
print(confusion_matrix1)
df <- as.data.frame(confusion_matrix1)
colnames(df) <- c('Actual','Predicted','Count')
library(ggplot2)
# Representing confusion matrix in a Heat Map
ggplot(df, aes(x = Predicted, y = Actual, fill = Count)) +
geom_tile() +
geom_text(aes(label = Count), color = "white", size = 5) +
scale_fill_gradient(low = "lightblue", high = "darkblue") +
ggtitle("Decision Tree Confusion Matrix Heatmap") +
xlab("Predicted Class") +
ylab("Actual Class")
# Accuracy of Decision tree model
accuracy_decision <- sum(diag(confusion_matrix1))/sum(confusion_matrix1)
print(paste("Decision Tree Accuracy : ", round(accuracy1*100,2),"%"))
library(rpart.plot)
# Decision Tree
rpart.plot(decision_tree)
library(caTools)
a$test_preparation_course <- factor(a$test_preparation_course)
set.seed(123)
split <- sample.split(a$test_preparation_course, SplitRatio = 0.7)
training_set <- subset(a, split == TRUE)
testing_set <- subset(a, split == FALSE)
str(training_set)
# Feature scaling (excluding target variable)
numeric_cols <- sapply(training_set, is.numeric)
training_set[numeric_cols] <- scale(training_set[numeric_cols])
testing_set[numeric_cols] <- scale(testing_set[numeric_cols])
library(e1071)
# Build Svm classifier
classifier <- svm(
formula = test_preparation_course ~ math_score + reading_score + writing_score,
data = training_set,
type = 'C-classification',
kernel = 'linear'
)
# Predicting the testing set results
y_pred <- predict(classifier, newdata = testing_set[-5])
# Confusion Matrix
confusion_matrix_svm <- table(testing_set$test_preparation_course, y_pred)
print(confusion_matrix_svm)
# Calculate SVM Accuracy
accuracy_svm <- sum(diag(confusion_matrix_svm)) / sum(confusion_matrix_svm)
print(paste("SVM Accuracy : ", round(accuracy_svm * 100, 2), "%"))
df_svm <- as.data.frame(confusion_matrix_svm)
colnames(df_svm) <- c('Actual', 'Predicted', 'Count')
library(ggplot2)
ggplot(df_svm, aes(x = Predicted, y = Actual, fill = Count)) +
geom_tile() +
geom_text(aes(label = Count), color = "white", size = 5) +
scale_fill_gradient(low = "lightblue", high = "darkblue") +
ggtitle("SVM Confusion Matrix Heatmap") +
xlab("Predicted Class") +
ylab("Actual Class")
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
numeric_cols1 <- sapply(a, is.numeric)
# Apply normalization only to numeric columns
a_norm <- as.data.frame(a) # Copy the original dataframe
a_norm[numeric_cols] <- lapply(a[numeric_cols], normalize)
# Splitting the dataset
train_idx <- 1:round(0.7 * nrow(a_norm))
concrete_train <- a_norm[train_idx, ]
concrete_test <- a_norm[-train_idx, ]
library(neuralnet)
# Build Neural Network
neural_model <- neuralnet(test_preparation_course ~ math_score + reading_score + writing_score,
data = concrete_train,
hidden = 5,
stepmax = 1e6,
rep = 1)
plot(neural_model)
# Predicting results using the neural network model
prediction_nn <- predict(neural_model, concrete_test)
# Confusion Matrix
confusion_matrix_nn <- table(concrete_test$test_preparation_course, prediction_nn)
print(confusion_matrix_nn)
# Calculatin Accuracy
accuracy_nn <- sum(diag(confusion_matrix_nn)) / sum(confusion_matrix_nn)
print(paste("Neural Network Accuracy : ", round(accuracy_nn * 100, 2), "%"))
# Heatmap Visualization
df_nn <- as.data.frame(confusion_matrix_nn)
colnames(df_nn) <- c('Actual', 'Predicted', 'Count')
library(ggplot2)
ggplot(df_nn, aes(x = Predicted, y = Actual, fill = Count)) +
geom_tile() +
geom_text(aes(label = Count), color = "white", size = 5) +
scale_fill_gradient(low = "lightblue", high = "darkblue") +
ggtitle("Neural Network Confusion Matrix Heatmap") +
xlab("Predicted Class") +
ylab("Actual Class")
library(arules)
library(cluster)
a_1=a[,-5]
set.seed(240)
kmeans_result <- kmeans(a[, c("math_score", "reading_score", "writing_score")], centers = 3, nstart = 20)
kmeans_result
print(kmeans_result$cluster)
print(kmeans_result$centers)
cm<-table(a$test_preparation_course,kmeans_result$cluster)
cm
plot(a_1[c("reading_score","writing_score")],
col=kmeans_result$cluster,
main="K-Means Clustering of Math, Reading, and Writing Scores"
)
# K-means Clustering
clusplot(a[, c("reading_score", "writing_score")],
kmeans_result$cluster,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 2,
plotchar = FALSE,
span = TRUE,
main = "K-Means Clustering of Students",
xlab = "Reading Score",
ylab = "Writing Score")
# Confusion Matrix
confusion_matrix_kmeans <- table(a$test_preparation_course, kmeans_result$cluster)
print(confusion_matrix_kmeans)
# Calculating Accuracy
accuracy_kmeans <- sum(diag(confusion_matrix_kmeans)) / sum(confusion_matrix_kmeans)
print(paste("K-Means Clustering Accuracy : ", round(accuracy_kmeans * 100, 2), "%"))
# Confusion matrix Visualization
df_kmeans <- as.data.frame(confusion_matrix_kmeans)
colnames(df_kmeans) <- c('Actual', 'Predicted', 'Count')
library(ggplot2)
ggplot(df_kmeans, aes(x = Predicted, y = Actual, fill = Count)) +
geom_tile() +
geom_text(aes(label = Count), color = "white", size = 5) +
scale_fill_gradient(low = "lightblue", high = "darkblue") +
ggtitle("K-Means Confusion Matrix Heatmap") +
xlab("Predicted Class") +
ylab("Actual Class")
model_accuracies <- data.frame(
Model = c("Naive Bayes", "Decision Tree", "SVM", "Neural Network", "K-Means"),
Accuracy = c(accuracy_naive * 100, accuracy_decision * 100, accuracy_svm * 100, accuracy_nn * 100, accuracy_kmeans * 100)
)
# Bar Plot
ggplot(model_accuracies, aes(x = Model, y = Accuracy, fill = Model)) +geom_bar(stat = "identity") +
geom_text(aes(label = round(Accuracy, 2)), vjust = -0.5, size = 5)+
ggtitle("Model Accuracy Comparison") +
xlab("Model") +
ylab("Accuracy (%)")
View(a)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
numeric_cols1 <- sapply(a, is.numeric)
# Apply normalization only to numeric columns
a_norm <- as.data.frame(a) # Copy the original dataframe
a_norm[numeric_cols] <- lapply(a[numeric_cols], normalize)
# Splitting the dataset
train_idx <- 1:round(0.7 * nrow(a_norm))
ann_train <- a_norm[train_idx, ]
ann_test <- a_norm[-train_idx, ]
# Install and load the neuralnet package
install.packages("neuralnet")
install.packages("neuralnet")
library(neuralnet)
# Build Neural Network
neural_model <- neuralnet(test_preparation_course ~ math_score + reading_score + writing_score,
data = ann_train,
hidden = 5,
stepmax = 1e6,
rep = 1)
# Predicting results using the neural network model
prediction_nn <- predict(neural_model, ann_test)
# Confusion Matrix
confusion_matrix_nn <- table(ann_test$test_preparation_course, prediction_nn)
print(confusion_matrix_nn)
# Calculatin Accuracy
accuracy_nn <- sum(diag(confusion_matrix_nn)) / sum(confusion_matrix_nn)
print(paste("Neural Network Accuracy : ", round(accuracy_nn * 100, 2), "%"))
ann_results<-compute(neural_model,concrete_test)
ann_pred_fraud<-ann_results$net.result
ann_results<-compute(neural_model,concrete_test)
ann_pred<-ann_results$net.result
cor(ann_pred,ann_test$test_preparation_course)
ch<-as.numeric(ann_test$test_preparation_course)
ann_results<-compute(neural_model,concrete_test)
ann_pred<-ann_results$net.result
cor(ann_pred,ann_test$test_preparation_course)
ch<-as.numeric(ann_test$test_preparation_course)
ann_results<-compute(neural_model,concrete_test)
ann_pred<-ann_results$net.result
cor(ann_pred,ch)
itemFrequencyPlot(groceries, support = 0.1)
install.packages("randomforest")
randomForest?
randomForest?
install.packages("randomForest")
install.packages("randomForest")
?randomForest
randomForest?
library(randomForest)
install.packages("randomForest")
library(randomForest)
data("iris")
data(iris)
set.seed(42)
sample_index<-sample(1:nrow(iris),0.7*nrow(iris))
train_data<-iris[sample_index,]
test_data<-iris[-sample_index,]
rf_model=randomForest(Species~.,data = train_data,ntree=100)
predictions<-predict(rf_model,test_data)
confusion_matrix<-table(predictions,test_data$Species)
print(confusion_matrix)
plot(rf_model)
accuracy<-sum(diag(confusion_matrix))/sum(confusion_matrix)
print(paste("Accuracy is: "+round(accuracy*100,2),"%"))
print(paste("Accuracy is: ",round(accuracy*100,2),"%"))
a<-10
a
class(a)
typeof(a)
data<-mtcars
a<-subset(data,data$mpg>15)
a
b<-ifelse(data$hp>150,"high","low")
b
summary(data)
dim(data)
colnames(data)
sum(is.na(data))
str(data)
sapply(data, class)
data$cyl<-factor(data$cyl)
data$cyl
unique(data$cyl)
summary(data$mpg)
hist(data$mpg,main="histogram",xlab="mpg",col="blue",border="black")
hist(data$mpg,main="histogram",xlab="mpg",col="blue",border="black",order=desc)
hist(data$mpg,main="histogram",xlab="mpg",col="blue",border="black")
boxplot(data$mpg,main="boxplot",horizontal = TRUE,col="orange")
boxplot(data$mpg,main="boxplot",horizontal = FALSE,col="orange")
boxplot(data$mpg,main="boxplot",col="orange")
boxplot(data$mpg,main="boxplot",horizontal=TRUE,col="orange")
boxplot(data$mpg,main="boxplot",col="orange")
hist(data$mpg,main="histogram",xlab="mpg")
table(data$cyl)
barplot(data$mpg,main="barplot",xlab="mpg",ylab="freq",col="green")
barplot(table(data$mpg),main="barplot",xlab="mpg",ylab="freq",col="green")
barplot(data$mpg,main="barplot",xlab="mpg",ylab="freq",col="green")
pie(table(data$cyl),main="piechart",col="red")
pie(table(data$cyl),main="piechart",col=rainbow(length(unique(data$cyl))))
plot(data$cyl,data$hp,main="scatterplot",xlab="cyl",ylab="hp",col="violet")
plot(data$cyl,data$hp,main="scatterplot",xlab="cyl",ylab="hp",col="violet",pch=19)
plot(data$cyl,data$hp,main="scatterplot",xlab="cyl",ylab="hp",col="violet")
cor(data$cyl,data$mpg)
cor(data$hp,data$mpg)
boxplot(mpg~cyl,data=data,main="boxplot",xlab="xyl",ylab="mpg",col="skyblue")
table(data$cyl,data$gear)
mosaicplot(table(data$cyl, data$gear), main = "Cylinders vs Gears", col = c("skyblue", "pink", "yellow"))
## dplyr
library(dplyr)
# Dplyr
library(dplyr)
head(data)
a<-data %>% select(cyl,mpg,hp)
a
filtered_data<- data %>% filter(mpg>20)
filtered_data
b<-data %>% mutate(performance=ifelse(hp>150,"high","low"))
b
id=c(1,2,3,4,5)
name=c('a','b','c','d','e')
marks=c(23,34,45,21,56)
df<-data.frame(id,name,marks)
df
library(sqldf)
sqldf("select * from df")
df<-sqldf(c("insert into df values(10,'rishith',88)","select * from df"))
df
df<-sqldf(c("insert into df values(10,'r',88)","select * from df"))
df
df<-sqldf(c("delete from df where id=3","select * from df"))
View(df)
df<-sqldf(c("update df set name='ankit' where id=1","select * from df"))
View(df)
emp=data.frame(empid=c(1,2,100,4,5,6),
name=c('a','b','c','d','e','f'),
salary=c(100,200,300,400,500,600),
dept=c('admin','manager','wager','worker','machinary','labour'))
emp
sqldf("select * from emp")
emp<-sqldf(c("insert into emp values(32,'w',900,'cooking')","select * from emp"))
View(emp)
emp<-sqldf(c("insert into emp values(44,'y',800,'washing')","select * from emp"))
emp
emp<-sqldf(c("delete from emp where dept='admin'","select * from emp"))
emp<-sqldf(c("update emp set dept='cleaning' where empid=100","select * from emp"))
# iris dataset
# display sepal width as sw from iris
# display max sepal width as max value
# then insert into iris values
# apply some function on petal length as some pl
# display species of versacile only
data=iris
View(data)
sqldf("select `Sepal.Width` as sw from data")
sqldf("select max([Sepal.Width]) as maxvalue from data")
sqldf("select sum([Petal.Length]) as sumpl from data")
sqldf("select * from data where species='versicolor'")
row<-c('row1','row2')
col<-c('col1','col2','col3')
matrix1<-matrix(1:6,nrow=2,ncol=3,dimnames = list(row,col))
matrix1<-matrix(1:6,nrow=2,ncol=3,dimnames = list(row,col))
matrix2<-matrix(7:12,nrow=2,ncol=3,dimnames=list(row,col))
matrix1
matrix2
matrix1+matrix2
matrix1[1,]
matrix2[2,3]
v1<-c("North","East","North","East","East")
a<-as.factor(v1)
b<-factor(v1)
b
a<-as.factor(v1)
a
a<-iris
diff(range(iris$Petal.Width))
quantile(iris$Petal.Width,seq(from=0,to=1,by=0.30))
diff(range(iris$Petal.Width))
diff(range(iris$Petal.Width))
quantile(iris$Petal.Width,seq(from=0,to=1,by=0.30))
table(iris$Sepal.Length)
b<-table(iris$Petal.Width)
prop.table(b)
getwd()
data<-data.frame(Name=c("Sai","Ram","Shyam"),
age=c(12,13,15))
data
save(data,file="abc.csv")
setwd("C:/College PPTs/5th SEM/INT234")
write.csv(data,file="abc.csv",row.names=FALSE)
ls()
rm(a,c)
ls()
write.csv(data,file="abc.csv",row.names=FALSE)
mydata<-read.csv("abc.csv")
View(mydata)
setwd("C:/College PPTs/5th SEM/INT234")
getwd()
a<-read.csv(file.choose())
View(a)
sum(is.na(a))
b<-na.omit(a)
b
sum(is.na(a))
sum(is.na(b))
# Remove duplicate rows
data <- a[!duplicated(a), ]
data
# Remove duplicate rows
data <- b[!duplicated(b), ]
data
# Remove duplicate rows
data <- a[!duplicated(a), ]
data
# Remove duplicate rows
data <- a[!duplicated(a), ]
data
# Rename a column
colnames(a)[colnames(a) == "Order.Date"] <- "Date"
View(a)
# Remove leading/trailing white spaces in a specific column
a$Customer.Name <- trimws(a$Customer.Name)
# Convert text to lowercase
a$Ship.Mode <- tolower(a$Ship.Mode)
# Convert text to uppercase
a$Ship.Mode <- toupper(a$Ship.Mode)
View(a)
# Rename a column
colnames(a)[colnames(a) == "Order.Date"] <- "Date"
View(a)
# Remove leading/trailing white spaces in a specific column
a$Customer.Name <- trimws(a$Customer.Name)
# Convert text to lowercase
a$Ship.Mode <- tolower(a$Ship.Mode)
# Convert text to uppercase
a$Ship.Mode <- toupper(a$Ship.Mode)
View(a)
a[is.na(a)]<-mean(a$sales,na.rm=TRUE)
# Replacing the missing values with the mean value of each variable
a$Sales[is.na(a$Sales)]<-mean(a$Sales,na.rm=TRUE)
View(a)
# Replacing the missing values with random value between min and max of each variable
a$Sales[is.na(a$Sales)]<-runif(n=sum(is.na(a$Sales)),
min=min(a$Sales,na.rm=TRUE),
max=max(a$Sales,na.rm=TRUE))
View(a)
# Missing values for categorical variables by random value from each variable
# Convert to factor if not already
a$Order.Priority <- as.factor(a$Order.Priority)
a$Order.Priority
# View the result
View(a)
a$Profit<-(a$profit-min(a$Profit))/(max(a$profit)-min(a$Profit))
a$Unit.Price<-(a$Unit.Price-min(a$Unit.Price))/(max(a$Unit.Price)-min(a$Unit.Price))
a$Unit.Price
a$Profit<-scale(a$Profit)
a$profit
# View the result
View(a)
a$Order.Priority
a$Order.Priority<-factor(a$Order.Priority)
a$Order.Priority
# Replace NA values with random levels from the factor
a$Order.Priority[is.na(a$Order.Priority)] <- sample(
levels(a$Order.Priority),
size = sum(is.na(a$Order.Priority)),
replace = TRUE
)
# View the result
View(a)
# Missing values for categorical variables by random value from each variable
# Convert to factor if not already
a$Order.Priority <- as.factor(a$Order.Priority)
a$Order.Priority
